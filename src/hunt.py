#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SUVç‰¹åŒ–å‹ Used-Car Scoutï¼ˆç²¾å¯†åˆ¤å®šç‰ˆ / DiscordäºŒæ®µéšé€šçŸ¥ï¼‰
æ”¹è‰¯ç‚¹:
- SUVåˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ã‚’å¤§å¹…å¼·åŒ–ï¼ˆè»Šç¨®DB + ã‚¿ã‚¤ãƒˆãƒ«è§£æ + è©³ç´°ãƒšãƒ¼ã‚¸ç¢ºèªï¼‰
- è»½è‡ªå‹•è»Šï¼ˆãƒã‚¹ãƒ©ãƒ¼ç­‰ï¼‰ã®ç¢ºå®Ÿãªé™¤å¤–
- è»Šç¨®æƒ…å ±ã®è©³ç´°å–å¾—ã¨æ¤œè¨¼
- ã‚ˆã‚Šæ­£ç¢ºãªç›¸å ´åˆ†æ

ç’°å¢ƒå¤‰æ•°:
  DISCORD_WEBHOOK_URL_MAIN  â€¦ å³è²·ã„ãƒ¬ãƒ™ãƒ«ã®é€šçŸ¥å…ˆï¼ˆå¿…é ˆæ¨å¥¨ï¼‰
  DISCORD_WEBHOOK_URL_MAYBE â€¦ ã‚ã‚Šã‹ã‚‚ãƒ¬ãƒ™ãƒ«ã®é€šçŸ¥å…ˆï¼ˆä»»æ„ï¼‰
  DISCORD_DRY_RUN           â€¦ "1" ãªã‚‰é€šçŸ¥ã›ãšã€é€ä¿¡å†…å®¹ã‚’ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«å‡ºåŠ›
  IMMEDIATE_URGENCY_MIN     â€¦ å³è²·ã„ãƒ¬ãƒ™ãƒ«ã®ç·Šæ€¥åº¦ã—ãã„å€¤ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ "4"ï¼‰
  MAYBE_SCORE_MIN           â€¦ ã‚ã‚Šã‹ã‚‚ãƒ¬ãƒ™ãƒ«ã®ã‚¹ã‚³ã‚¢ä¸‹é™ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ "70"ï¼‰
"""
from __future__ import annotations
import os, re, csv, json, time, math, random
from datetime import datetime
from typing import List, Dict, Any, Optional, Set, Tuple
from unicodedata import normalize
from dataclasses import dataclass, field

import requests
from bs4 import BeautifulSoup
import numpy as np
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.model_selection import KFold

# ========== é€šä¿¡è¨­å®š ==========
UA_LIST = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:124.0) Gecko/20100101 Firefox/124.0"
]

def get_headers():
    return {
        "User-Agent": random.choice(UA_LIST),
        "Accept-Language": "ja,en;q=0.9",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
        "Accept-Encoding": "gzip, deflate, br",
        "DNT": "1",
        "Connection": "keep-alive",
        "Upgrade-Insecure-Requests": "1"
    }

# ========== SUVè»Šç¨®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ ==========
@dataclass
class VehicleModel:
    """è»Šç¨®æƒ…å ±"""
    maker: str
    model: str
    name_variants: Set[str] = field(default_factory=set)
    is_suv: bool = True
    is_kei: bool = False  # è»½è‡ªå‹•è»Šãƒ•ãƒ©ã‚°
    body_types: Set[str] = field(default_factory=set)
    
SUV_DATABASE = {
    # ãƒˆãƒ¨ã‚¿
    "ãƒãƒªã‚¢ãƒ¼": VehicleModel("ãƒˆãƒ¨ã‚¿", "ãƒãƒªã‚¢ãƒ¼", {"HARRIER", "harrier"}, True, False, {"SUV", "ã‚¯ãƒ­ã‚¹ã‚ªãƒ¼ãƒãƒ¼SUV"}),
    "RAV4": VehicleModel("ãƒˆãƒ¨ã‚¿", "RAV4", {"ãƒ©ãƒ´ãƒ•ã‚©ãƒ¼", "ãƒ©ãƒ–ãƒ•ã‚©ãƒ¼"}, True, False, {"SUV", "ã‚¯ãƒ­ã‚¹ã‚ªãƒ¼ãƒãƒ¼SUV"}),
    "ãƒ©ãƒ³ãƒ‰ã‚¯ãƒ«ãƒ¼ã‚¶ãƒ¼": VehicleModel("ãƒˆãƒ¨ã‚¿", "ãƒ©ãƒ³ãƒ‰ã‚¯ãƒ«ãƒ¼ã‚¶ãƒ¼", {"LANDCRUISER", "ãƒ©ãƒ³ã‚¯ãƒ«", "LC"}, True, False, {"SUV", "ã‚¯ãƒ­ã‚«ãƒ³"}),
    "ãƒ©ãƒ³ãƒ‰ã‚¯ãƒ«ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ©ãƒ‰": VehicleModel("ãƒˆãƒ¨ã‚¿", "ãƒ—ãƒ©ãƒ‰", {"PRADO", "ãƒ©ãƒ³ã‚¯ãƒ«ãƒ—ãƒ©ãƒ‰"}, True, False, {"SUV", "ã‚¯ãƒ­ã‚«ãƒ³"}),
    "C-HR": VehicleModel("ãƒˆãƒ¨ã‚¿", "C-HR", {"CHR", "chr"}, True, False, {"SUV", "ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆSUV"}),
    "ã‚«ãƒ­ãƒ¼ãƒ©ã‚¯ãƒ­ã‚¹": VehicleModel("ãƒˆãƒ¨ã‚¿", "ã‚«ãƒ­ãƒ¼ãƒ©ã‚¯ãƒ­ã‚¹", {"COROLLA CROSS"}, True, False, {"SUV"}),
    "ãƒ¤ãƒªã‚¹ã‚¯ãƒ­ã‚¹": VehicleModel("ãƒˆãƒ¨ã‚¿", "ãƒ¤ãƒªã‚¹ã‚¯ãƒ­ã‚¹", {"YARIS CROSS"}, True, False, {"SUV", "ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆSUV"}),
    "ãƒ©ã‚¤ã‚º": VehicleModel("ãƒˆãƒ¨ã‚¿", "ãƒ©ã‚¤ã‚º", {"RAIZE"}, True, False, {"SUV", "ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆSUV"}),
    "ãƒã‚¤ãƒ©ãƒƒã‚¯ã‚¹": VehicleModel("ãƒˆãƒ¨ã‚¿", "ãƒã‚¤ãƒ©ãƒƒã‚¯ã‚¹", {"HILUX"}, True, False, {"ãƒ”ãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒˆãƒ©ãƒƒã‚¯", "SUV"}),
    
    # æ—¥ç”£
    "ã‚¨ã‚¯ã‚¹ãƒˆãƒ¬ã‚¤ãƒ«": VehicleModel("æ—¥ç”£", "ã‚¨ã‚¯ã‚¹ãƒˆãƒ¬ã‚¤ãƒ«", {"X-TRAIL", "XTRAIL"}, True, False, {"SUV"}),
    "ã‚­ãƒƒã‚¯ã‚¹": VehicleModel("æ—¥ç”£", "ã‚­ãƒƒã‚¯ã‚¹", {"KICKS", "e-POWER"}, True, False, {"SUV", "ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆSUV"}),
    "ã‚¸ãƒ¥ãƒ¼ã‚¯": VehicleModel("æ—¥ç”£", "ã‚¸ãƒ¥ãƒ¼ã‚¯", {"JUKE"}, True, False, {"SUV", "ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆSUV"}),
    "ãƒ ãƒ©ãƒ¼ãƒ": VehicleModel("æ—¥ç”£", "ãƒ ãƒ©ãƒ¼ãƒ", {"MURANO"}, True, False, {"SUV"}),
    "ãƒ†ãƒ©ãƒ": VehicleModel("æ—¥ç”£", "ãƒ†ãƒ©ãƒ", {"TERRANO"}, True, False, {"SUV", "ã‚¯ãƒ­ã‚«ãƒ³"}),
    "ã‚¢ãƒªã‚¢": VehicleModel("æ—¥ç”£", "ã‚¢ãƒªã‚¢", {"ARIYA"}, True, False, {"SUV", "é›»æ°—è‡ªå‹•è»Š"}),
    
    # ãƒ›ãƒ³ãƒ€
    "ãƒ´ã‚§ã‚¼ãƒ«": VehicleModel("ãƒ›ãƒ³ãƒ€", "ãƒ´ã‚§ã‚¼ãƒ«", {"VEZEL", "ãƒ™ã‚¼ãƒ«"}, True, False, {"SUV", "ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆSUV"}),
    "CR-V": VehicleModel("ãƒ›ãƒ³ãƒ€", "CR-V", {"CRV", "ã‚·ãƒ¼ã‚¢ãƒ¼ãƒ«ãƒ–ã‚¤"}, True, False, {"SUV"}),
    "ZR-V": VehicleModel("ãƒ›ãƒ³ãƒ€", "ZR-V", {"ZRV"}, True, False, {"SUV"}),
    
    # ãƒãƒ„ãƒ€
    "CX-3": VehicleModel("ãƒãƒ„ãƒ€", "CX-3", {"cx3", "ã‚·ãƒ¼ã‚¨ãƒƒã‚¯ã‚¹ã‚¹ãƒªãƒ¼"}, True, False, {"SUV", "ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆSUV"}),
    "CX-30": VehicleModel("ãƒãƒ„ãƒ€", "CX-30", {"cx30", "ã‚·ãƒ¼ã‚¨ãƒƒã‚¯ã‚¹ã‚µãƒ¼ãƒ†ã‚£ãƒ¼"}, True, False, {"SUV"}),
    "CX-5": VehicleModel("ãƒãƒ„ãƒ€", "CX-5", {"cx5", "ã‚·ãƒ¼ã‚¨ãƒƒã‚¯ã‚¹ãƒ•ã‚¡ã‚¤ãƒ–"}, True, False, {"SUV"}),
    "CX-8": VehicleModel("ãƒãƒ„ãƒ€", "CX-8", {"cx8", "ã‚·ãƒ¼ã‚¨ãƒƒã‚¯ã‚¹ã‚¨ã‚¤ãƒˆ"}, True, False, {"SUV", "3åˆ—ã‚·ãƒ¼ãƒˆ"}),
    "CX-60": VehicleModel("ãƒãƒ„ãƒ€", "CX-60", {"cx60"}, True, False, {"SUV"}),
    "MX-30": VehicleModel("ãƒãƒ„ãƒ€", "MX-30", {"mx30"}, True, False, {"SUV", "é›»å‹•"}),
    
    # ã‚¹ãƒãƒ«
    "ãƒ•ã‚©ãƒ¬ã‚¹ã‚¿ãƒ¼": VehicleModel("ã‚¹ãƒãƒ«", "ãƒ•ã‚©ãƒ¬ã‚¹ã‚¿ãƒ¼", {"FORESTER"}, True, False, {"SUV"}),
    "XV": VehicleModel("ã‚¹ãƒãƒ«", "XV", {"CROSSTREK", "ã‚¯ãƒ­ã‚¹ãƒˆãƒ¬ãƒƒã‚¯"}, True, False, {"SUV", "ã‚¯ãƒ­ã‚¹ã‚ªãƒ¼ãƒãƒ¼"}),
    "ãƒ¬ã‚¬ã‚·ã‚£ã‚¢ã‚¦ãƒˆãƒãƒƒã‚¯": VehicleModel("ã‚¹ãƒãƒ«", "ã‚¢ã‚¦ãƒˆãƒãƒƒã‚¯", {"OUTBACK", "ãƒ¬ã‚¬ã‚·ã‚£"}, True, False, {"SUV", "ã‚¯ãƒ­ã‚¹ã‚ªãƒ¼ãƒãƒ¼"}),
    "ã‚¢ã‚»ãƒ³ãƒˆ": VehicleModel("ã‚¹ãƒãƒ«", "ã‚¢ã‚»ãƒ³ãƒˆ", {"ASCENT"}, True, False, {"SUV", "3åˆ—ã‚·ãƒ¼ãƒˆ"}),
    
    # ä¸‰è±
    "ã‚¢ã‚¦ãƒˆãƒ©ãƒ³ãƒ€ãƒ¼": VehicleModel("ä¸‰è±", "ã‚¢ã‚¦ãƒˆãƒ©ãƒ³ãƒ€ãƒ¼", {"OUTLANDER", "PHEV"}, True, False, {"SUV"}),
    "ã‚¨ã‚¯ãƒªãƒ—ã‚¹ã‚¯ãƒ­ã‚¹": VehicleModel("ä¸‰è±", "ã‚¨ã‚¯ãƒªãƒ—ã‚¹ã‚¯ãƒ­ã‚¹", {"ECLIPSE CROSS"}, True, False, {"SUV"}),
    "RVR": VehicleModel("ä¸‰è±", "RVR", {"ã‚¢ãƒ¼ãƒ«ãƒ–ã‚¤ã‚¢ãƒ¼ãƒ«"}, True, False, {"SUV", "ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆSUV"}),
    "ãƒ‘ã‚¸ã‚§ãƒ­": VehicleModel("ä¸‰è±", "ãƒ‘ã‚¸ã‚§ãƒ­", {"PAJERO"}, True, False, {"SUV", "ã‚¯ãƒ­ã‚«ãƒ³"}),
    
    # ã‚¹ã‚ºã‚­ï¼ˆè»½è‡ªå‹•è»Šã¯é™¤å¤–å¯¾è±¡ï¼‰
    "ã‚¸ãƒ ãƒ‹ãƒ¼": VehicleModel("ã‚¹ã‚ºã‚­", "ã‚¸ãƒ ãƒ‹ãƒ¼", {"JIMNY"}, True, True, {"è»½è‡ªå‹•è»Š", "ã‚¯ãƒ­ã‚«ãƒ³"}),
    "ã‚¸ãƒ ãƒ‹ãƒ¼ã‚·ã‚¨ãƒ©": VehicleModel("ã‚¹ã‚ºã‚­", "ã‚¸ãƒ ãƒ‹ãƒ¼ã‚·ã‚¨ãƒ©", {"JIMNY SIERRA"}, True, False, {"SUV", "ã‚¯ãƒ­ã‚«ãƒ³"}),
    "ã‚¨ã‚¹ã‚¯ãƒ¼ãƒ‰": VehicleModel("ã‚¹ã‚ºã‚­", "ã‚¨ã‚¹ã‚¯ãƒ¼ãƒ‰", {"ESCUDO"}, True, False, {"SUV"}),
    "ã‚¯ãƒ­ã‚¹ãƒ“ãƒ¼": VehicleModel("ã‚¹ã‚ºã‚­", "ã‚¯ãƒ­ã‚¹ãƒ“ãƒ¼", {"XBEE", "CROSSBEE"}, True, False, {"SUV", "ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆSUV"}),
    "ãƒã‚¹ãƒ©ãƒ¼": VehicleModel("ã‚¹ã‚ºã‚­", "ãƒã‚¹ãƒ©ãƒ¼", {"HUSTLER"}, False, True, {"è»½è‡ªå‹•è»Š", "è»½SUV"}),
    "ã‚¹ãƒšãƒ¼ã‚·ã‚¢ã‚®ã‚¢": VehicleModel("ã‚¹ã‚ºã‚­", "ã‚¹ãƒšãƒ¼ã‚·ã‚¢ã‚®ã‚¢", {"SPACIA GEAR"}, False, True, {"è»½è‡ªå‹•è»Š"}),
    
    # ãƒ€ã‚¤ãƒãƒ„ï¼ˆè»½è‡ªå‹•è»Šï¼‰
    "ã‚¿ãƒ•ãƒˆ": VehicleModel("ãƒ€ã‚¤ãƒãƒ„", "ã‚¿ãƒ•ãƒˆ", {"TAFT"}, False, True, {"è»½è‡ªå‹•è»Š", "è»½SUV"}),
    "ãƒ­ãƒƒã‚­ãƒ¼": VehicleModel("ãƒ€ã‚¤ãƒãƒ„", "ãƒ­ãƒƒã‚­ãƒ¼", {"ROCKY"}, True, False, {"SUV", "ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆSUV"}),
    "ãƒ†ãƒªã‚ªã‚¹ã‚­ãƒƒãƒ‰": VehicleModel("ãƒ€ã‚¤ãƒãƒ„", "ãƒ†ãƒªã‚ªã‚¹ã‚­ãƒƒãƒ‰", {"TERIOS KID"}, False, True, {"è»½è‡ªå‹•è»Š"}),
}

# è»½è‡ªå‹•è»Šã®ç¢ºå®Ÿãªé™¤å¤–ãƒªã‚¹ãƒˆ
KEI_CAR_KEYWORDS = {
    "ãƒã‚¹ãƒ©ãƒ¼", "HUSTLER", "ã‚¿ãƒ•ãƒˆ", "TAFT", "ã‚¹ãƒšãƒ¼ã‚·ã‚¢ã‚®ã‚¢", "SPACIA GEAR",
    "ãƒ†ãƒªã‚ªã‚¹ã‚­ãƒƒãƒ‰", "TERIOS KID", "ã‚­ãƒ£ã‚¹ãƒˆ", "CAST", "ã‚¢ã‚¯ãƒ†ã‚£ãƒ", "ACTIVA",
    "ã‚¦ã‚§ã‚¤ã‚¯", "WAKE", "è»½è‡ªå‹•è»Š", "è»½SUV", "K-CAR", "660cc", "660CC"
}

# ========== è»Šç¨®åˆ¤å®šã‚¨ãƒ³ã‚¸ãƒ³ ==========
class VehicleClassifier:
    """è»Šç¨®åˆ¤å®šã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.suv_patterns = self._compile_patterns()
        self.kei_patterns = re.compile(
            r'(è»½è‡ªå‹•è»Š|è»½SUV|660cc|660CC|K-?CAR)', 
            re.IGNORECASE
        )
        
    def _compile_patterns(self) -> Dict[str, re.Pattern]:
        """SUVãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«"""
        patterns = {}
        for key, model in SUV_DATABASE.items():
            if model.is_suv and not model.is_kei:
                # ãƒ¡ã‚¤ãƒ³ã®è»Šç¨®åã¨åˆ¥åã‚’ãƒ‘ã‚¿ãƒ¼ãƒ³åŒ–
                all_names = {key, model.model} | model.name_variants
                pattern_str = '|'.join(re.escape(name) for name in all_names)
                patterns[key] = re.compile(pattern_str, re.IGNORECASE)
        return patterns
    
    def classify(self, text: str, detailed_text: str = "") -> Tuple[bool, str, float]:
        """
        ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰SUVåˆ¤å®š
        Returns: (is_suv, model_name, confidence)
        """
        normalized = normalize("NFKC", text.upper())
        detailed_norm = normalize("NFKC", detailed_text.upper()) if detailed_text else ""
        
        # è»½è‡ªå‹•è»Šãƒã‚§ãƒƒã‚¯ï¼ˆé™¤å¤–ï¼‰
        if self._is_kei_car(normalized + " " + detailed_norm):
            return False, "è»½è‡ªå‹•è»Š", 0.0
        
        # SUVãƒ¢ãƒ‡ãƒ«æ¤œå‡º
        for model_key, pattern in self.suv_patterns.items():
            if pattern.search(text) or (detailed_text and pattern.search(detailed_text)):
                model = SUV_DATABASE[model_key]
                confidence = self._calculate_confidence(text, detailed_text, model)
                return True, model_key, confidence
        
        # SUVé–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒã‚§ãƒƒã‚¯ï¼ˆå¼±ã„åˆ¤å®šï¼‰
        suv_keywords = {"SUV", "ã‚¯ãƒ­ã‚¹ã‚ªãƒ¼ãƒãƒ¼", "ã‚¯ãƒ­ã‚«ãƒ³", "4WD", "AWD", "ã‚ªãƒ•ãƒ­ãƒ¼ãƒ‰"}
        if any(kw in normalized for kw in suv_keywords):
            return True, "ä¸æ˜SUV", 0.3
        
        return False, "", 0.0
    
    def _is_kei_car(self, text: str) -> bool:
        """è»½è‡ªå‹•è»Šåˆ¤å®š"""
        for kw in KEI_CAR_KEYWORDS:
            if kw.upper() in text:
                return True
        if self.kei_patterns.search(text):
            return True
        return False
    
    def _calculate_confidence(self, title: str, detail: str, model: VehicleModel) -> float:
        """ä¿¡é ¼åº¦è¨ˆç®—"""
        confidence = 0.7  # ãƒ™ãƒ¼ã‚¹ä¿¡é ¼åº¦
        
        # ãƒ¡ãƒ¼ã‚«ãƒ¼åãŒå«ã¾ã‚Œã¦ã„ã‚Œã°ä¿¡é ¼åº¦UP
        if model.maker in title or model.maker in detail:
            confidence += 0.15
        
        # ãƒœãƒ‡ã‚£ã‚¿ã‚¤ãƒ—ãŒä¸€è‡´ã™ã‚Œã°ä¿¡é ¼åº¦UP  
        for body_type in model.body_types:
            if body_type in title or body_type in detail:
                confidence += 0.1
                break
        
        # è¤‡æ•°ã®åˆ¥åãŒå«ã¾ã‚Œã¦ã„ã‚Œã°ä¿¡é ¼åº¦UP
        variant_count = sum(1 for v in model.name_variants if v.upper() in title.upper())
        confidence += min(variant_count * 0.05, 0.15)
        
        return min(confidence, 1.0)

# ========== è©³ç´°ãƒšãƒ¼ã‚¸å–å¾— ==========
def fetch_with_retry(url: str, max_retries: int = 2) -> Optional[str]:
    """ãƒªãƒˆãƒ©ã‚¤ä»˜ããƒ•ã‚§ãƒƒãƒ"""
    for attempt in range(max_retries + 1):
        try:
            time.sleep(random.uniform(1.0, 2.0))  # ãƒ©ãƒ³ãƒ€ãƒ å¾…æ©Ÿ
            r = requests.get(url, headers=get_headers(), timeout=15)
            r.raise_for_status()
            return r.text
        except Exception as e:
            if attempt == max_retries:
                print(f"[ERROR] Failed to fetch {url}: {e}")
                return None
            time.sleep(2 ** attempt)  # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•
    return None

def extract_vehicle_details(url: str, site: str) -> Dict[str, Any]:
    """è©³ç´°ãƒšãƒ¼ã‚¸ã‹ã‚‰è»Šä¸¡æƒ…å ±ã‚’æŠ½å‡º"""
    html = fetch_with_retry(url)
    if not html:
        return {}
    
    soup = BeautifulSoup(html, "lxml")
    details = {}
    
    if site == "carsensor":
        # ã‚«ãƒ¼ã‚»ãƒ³ã‚µãƒ¼ã®è©³ç´°æƒ…å ±å–å¾—
        details["body_type"] = _extract_text(soup, ".specWrap th:contains('ãƒœãƒ‡ã‚£ã‚¿ã‚¤ãƒ—') + td")
        details["model_year"] = _extract_text(soup, ".specWrap th:contains('å¹´å¼') + td")
        details["grade"] = _extract_text(soup, ".specWrap th:contains('ã‚°ãƒ¬ãƒ¼ãƒ‰') + td")
        details["engine"] = _extract_text(soup, ".specWrap th:contains('æ’æ°—é‡') + td")
        details["drive_type"] = _extract_text(soup, ".specWrap th:contains('é§†å‹•æ–¹å¼') + td")
        details["color"] = _extract_text(soup, ".specWrap th:contains('è»Šä½“è‰²') + td")
        details["equipment"] = _extract_equipment_carsensor(soup)
        
    elif site == "goonet":
        # Goo-netã®è©³ç´°æƒ…å ±å–å¾—
        details["body_type"] = _extract_text(soup, "th:contains('ãƒœãƒ‡ã‚£ã‚¿ã‚¤ãƒ—') + td")
        details["model_year"] = _extract_text(soup, "th:contains('å¹´å¼') + td")
        details["grade"] = _extract_text(soup, "th:contains('ã‚°ãƒ¬ãƒ¼ãƒ‰') + td")
        details["engine"] = _extract_text(soup, "th:contains('æ’æ°—é‡') + td")
        details["drive_type"] = _extract_text(soup, "th:contains('é§†å‹•') + td")
        details["equipment"] = _extract_equipment_goonet(soup)
    
    # èª¬æ˜æ–‡ã‹ã‚‰è¿½åŠ æƒ…å ±
    description = soup.get_text(" ", strip=True)[:2000]  # æœ€åˆã®2000æ–‡å­—
    details["description"] = description
    
    return details

def _extract_text(soup, selector: str) -> str:
    """ã‚»ãƒ¬ã‚¯ã‚¿ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º"""
    elem = soup.select_one(selector)
    return elem.get_text(strip=True) if elem else ""

def _extract_equipment_carsensor(soup) -> List[str]:
    """ã‚«ãƒ¼ã‚»ãƒ³ã‚µãƒ¼ã‹ã‚‰è£…å‚™æŠ½å‡º"""
    equipment = []
    equip_section = soup.select(".equipment li, .equipmentList li")
    for item in equip_section[:20]:  # æœ€å¤§20å€‹
        equipment.append(item.get_text(strip=True))
    return equipment

def _extract_equipment_goonet(soup) -> List[str]:
    """Goo-netã‹ã‚‰è£…å‚™æŠ½å‡º"""
    equipment = []
    equip_section = soup.select(".equipment span, .icon-list li")
    for item in equip_section[:20]:
        equipment.append(item.get_text(strip=True))
    return equipment

# ========== ãƒ‘ãƒ¼ã‚µãƒ¼æ”¹è‰¯ç‰ˆ ==========
def parse_carsensor_list_enhanced(html: str) -> List[Dict[str, Any]]:
    """ã‚«ãƒ¼ã‚»ãƒ³ã‚µãƒ¼ã®ãƒªã‚¹ãƒˆãƒšãƒ¼ã‚¸è§£æï¼ˆå¼·åŒ–ç‰ˆï¼‰"""
    soup = BeautifulSoup(html, "lxml")
    items = []
    classifier = VehicleClassifier()
    
    # è»Šä¸¡ã‚«ãƒ¼ãƒ‰ã‚’å–å¾—
    cards = soup.select(".cassette__inner, .cassetteMain, .js-listTableCassette")
    if not cards:
        cards = soup.select("article, .itemBox")
    
    for card in cards:
        try:
            # åŸºæœ¬æƒ…å ±å–å¾—
            title_elem = card.select_one("h3 a, .cassetteMain__title a, h2 a")
            if not title_elem:
                continue
                
            title = title_elem.get_text(strip=True)
            url = title_elem.get("href", "")
            if url.startswith("/"):
                url = "https://www.carsensor.net" + url
            
            # è»Šç¨®åˆ¤å®šï¼ˆç¬¬1æ®µéšï¼‰
            is_suv, model_name, confidence = classifier.classify(title)
            if not is_suv or confidence < 0.3:
                continue  # SUVã§ãªã„ or ä¿¡é ¼åº¦ãŒä½ã„
            
            # ä¾¡æ ¼ãƒ»å¹´å¼ãƒ»èµ°è¡Œè·é›¢ã®æŠ½å‡º
            text = card.get_text(" ", strip=True)
            price = _extract_price(text)
            year = _extract_year(text)
            mileage = _extract_mileage(text)
            
            # ãƒœãƒ‡ã‚£ã‚¿ã‚¤ãƒ—ã®ç¢ºèªï¼ˆå¯èƒ½ãªå ´åˆï¼‰
            body_type_elem = card.select_one(".cassetteMain__etc span:contains('SUV'), .bodyType")
            body_type = body_type_elem.get_text(strip=True) if body_type_elem else ""
            
            # ä¿®å¾©æ­´ãƒã‚§ãƒƒã‚¯
            has_repair = "ä¿®å¾©æ­´ã‚ã‚Š" in text or "R" in text
            
            # ã‚°ãƒ¬ãƒ¼ãƒ‰æƒ…å ±
            grade_elem = card.select_one(".cassetteMain__grade, .grade")
            grade = grade_elem.get_text(strip=True) if grade_elem else ""
            
            items.append({
                "title": title,
                "url": url,
                "year": year,
                "mileage": mileage,
                "price": price,
                "site": "carsensor",
                "model_name": model_name,
                "confidence": confidence,
                "body_type": body_type,
                "grade": grade,
                "has_repair": has_repair,
                "raw_text": text[:500]  # ãƒ‡ãƒãƒƒã‚°ç”¨
            })
            
        except Exception as e:
            print(f"[WARN] Parse error: {e}")
            continue
    
    return items

def parse_goonet_list_enhanced(html: str) -> List[Dict[str, Any]]:
    """Goo-netã®ãƒªã‚¹ãƒˆãƒšãƒ¼ã‚¸è§£æï¼ˆå¼·åŒ–ç‰ˆï¼‰"""
    soup = BeautifulSoup(html, "lxml")
    items = []
    classifier = VehicleClassifier()
    
    # è»Šä¸¡è¦ç´ ã‚’å–å¾—
    cars = soup.select(".car-list-unit, .used-car-list-wrap article, .item-wrap")
    
    for car in cars:
        try:
            title_elem = car.select_one("h3 a, h2 a, .item-name a")
            if not title_elem:
                continue
                
            title = title_elem.get_text(strip=True)
            url = title_elem.get("href", "")
            if not url.startswith("http"):
                url = "https://www.goo-net.com" + url
            
            # SUVåˆ¤å®š
            is_suv, model_name, confidence = classifier.classify(title)
            if not is_suv or confidence < 0.3:
                continue
            
            text = car.get_text(" ", strip=True)
            price = _extract_price(text)
            year = _extract_year(text)
            mileage = _extract_mileage(text)
            
            # ã‚°ãƒ¬ãƒ¼ãƒ‰ãƒ»è‰²æƒ…å ±
            spec_elem = car.select_one(".spec-wrap, .item-spec")
            grade = spec_elem.get_text(strip=True) if spec_elem else ""
            
            items.append({
                "title": title,
                "url": url,
                "year": year,
                "mileage": mileage,
                "price": price,
                "site": "goonet",
                "model_name": model_name,
                "confidence": confidence,
                "grade": grade,
                "raw_text": text[:500]
            })
            
        except Exception as e:
            print(f"[WARN] Parse error: {e}")
            continue
    
    return items

# ========== æ•°å€¤æŠ½å‡ºãƒ˜ãƒ«ãƒ‘ãƒ¼ ==========
def _extract_price(text: str) -> int:
    """ä¾¡æ ¼æŠ½å‡ºï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
    patterns = [
        r"([0-9,]+(?:\.[0-9]+)?)\s*ä¸‡å††",
        r"ï¿¥([0-9,]+)",
        r"([0-9,]+)å††"
    ]
    for pattern in patterns:
        m = re.search(pattern, text)
        if m:
            val = m.group(1).replace(",", "")
            if "ä¸‡å††" in m.group(0):
                return int(float(val) * 10000)
            return int(float(val))
    return 0

def _extract_year(text: str) -> int:
    """å¹´å¼æŠ½å‡º"""
    patterns = [
        r"(\d{4})å¹´å¼",
        r"(\d{4})å¹´",
        r"H(\d{2})å¹´",  # å¹³æˆ
        r"R(\d{1,2})å¹´"  # ä»¤å’Œ
    ]
    for pattern in patterns:
        m = re.search(pattern, text)
        if m:
            if pattern.startswith("H"):
                return 1988 + int(m.group(1))  # å¹³æˆå¤‰æ›
            elif pattern.startswith("R"):
                return 2018 + int(m.group(1))  # ä»¤å’Œå¤‰æ›
            else:
                year = int(m.group(1))
                if 2000 <= year <= 2030:
                    return year
    return 0

def _extract_mileage(text: str) -> int:
    """èµ°è¡Œè·é›¢æŠ½å‡º"""
    patterns = [
        r"([0-9.]+)\s*ä¸‡\s*km",
        r"([0-9,]+)\s*km"
    ]
    for pattern in patterns:
        m = re.search(pattern, text, re.IGNORECASE)
        if m:
            val = m.group(1).replace(",", "")
            if "ä¸‡" in m.group(0):
                return int(float(val) * 10000)
            return int(float(val))
    return 0

# ========== è©•ä¾¡ã‚¨ãƒ³ã‚¸ãƒ³ï¼ˆæ”¹è‰¯ç‰ˆï¼‰ ==========
def compute_enhanced_score(item: Dict[str, Any], market_stats: Dict, config: Dict) -> None:
    """å¼·åŒ–ç‰ˆã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°"""
    price = item.get("price", 0)
    year = item.get("year", 0)
    mileage = item.get("mileage", 0)
    confidence = item.get("confidence", 0.5)
    
    if not price:
        item["score"] = 0
        item["urgency"] = 0
        return
    
    # åŸºæœ¬ã‚¹ã‚³ã‚¢è¨ˆç®—
    base_score = 50
    
    # ä¾¡æ ¼è©•ä¾¡
    median_price = market_stats.get("median", 0)
    if median_price:
        price_ratio = price / median_price
        if price_ratio <= 0.6:
            base_score = 95
        elif price_ratio <= 0.7:
            base_score = 85
        elif price_ratio <= 0.8:
            base_score = 75
        elif price_ratio <= 0.9:
            base_score = 65
        item["price_ratio"] = round(price_ratio, 2)
    
    # å¹´å¼è©•ä¾¡
    current_year = datetime.now().year
    age = current_year - year if year else 99
    if age <= 3:
        base_score += 15
    elif age <= 5:
        base_score += 10
    elif age <= 8:
        base_score += 5
    elif age >= 15:
        base_score -= 10
    
    # èµ°è¡Œè·é›¢è©•ä¾¡
    if mileage:
        annual_mileage = mileage / max(age, 1)
        if annual_mileage <= 5000:
            base_score += 15
        elif annual_mileage <= 8000:
            base_score += 10
        elif annual_mileage <= 12000:
            base_score += 5
        elif annual_mileage >= 20000:
            base_score -= 10
    
    # SUVä¿¡é ¼åº¦ã«ã‚ˆã‚‹èª¿æ•´
    base_score = base_score * (0.7 + 0.3 * confidence)
    
    # è£…å‚™ã«ã‚ˆã‚‹åŠ ç‚¹
    title = item.get("title", "")
    premium_keywords = [
        "ã‚µãƒ³ãƒ«ãƒ¼ãƒ•", "ãƒ¬ã‚¶ãƒ¼", "é©ã‚·ãƒ¼ãƒˆ", "BOSE", "JBL", 
        "ãƒãƒ¼ã‚¯ãƒ¬ãƒ“ãƒ³ã‚½ãƒ³", "360åº¦", "ãƒ—ãƒ­ãƒ‘ã‚¤ãƒ­ãƒƒãƒˆ", "ã‚¢ã‚¤ã‚µã‚¤ãƒˆ",
        "ãƒãƒ³ã‚ºãƒ•ãƒªãƒ¼", "é›»å‹•ãƒªã‚¢ã‚²ãƒ¼ãƒˆ", "ãƒãƒˆãƒªã‚¯ã‚¹LED"
    ]
    for kw in premium_keywords:
        if kw in title:
            base_score += 2
    
    # ä¿®å¾©æ­´ã«ã‚ˆã‚‹æ¸›ç‚¹
    if item.get("has_repair"):
        base_score -= 25
    
    # äºˆæ¸¬ä¾¡æ ¼ã¨ã®å·®é¡è©•ä¾¡
    if "pred_p50" in item and item["pred_p50"]:
        gap = item["pred_p50"] - price
        if gap > 500000:
            base_score += 10
        elif gap > 300000:
            base_score += 7
        elif gap > 100000:
            base_score += 4
        item["deal_gap"] = int(gap)
    
    # ã‚¹ã‚³ã‚¢æ­£è¦åŒ–
    score = max(0, min(100, base_score))
    
    # ç·Šæ€¥åº¦åˆ¤å®š
    if score >= 90:
        urgency = 5
    elif score >= 80:
        urgency = 4
    elif score >= 70:
        urgency = 3
    elif score >= 60:
        urgency = 2
    else:
        urgency = 1
    
    # ç‰¹åˆ¥æ¡ä»¶ã«ã‚ˆã‚‹ç·Šæ€¥åº¦ãƒ–ãƒ¼ã‚¹ãƒˆ
    if median_price and price <= median_price * 0.6:
        urgency = min(5, urgency + 1)
    
    item["score"] = round(score, 1)
    item["urgency"] = urgency

# ========== åˆ†ä½å›å¸°äºˆæ¸¬ ==========
def build_features(item: Dict[str, Any]) -> List[float]:
    """ç‰¹å¾´é‡æ§‹ç¯‰ï¼ˆæ‹¡å¼µç‰ˆï¼‰"""
    title = item.get("title", "")
    current_year = datetime.now().year
    
    features = [
        item.get("year", 0),
        item.get("mileage", 0),
        current_year - item.get("year", current_year) if item.get("year") else 15,  # è»Šé½¢
        item.get("confidence", 0.5),  # SUVåˆ¤å®šä¿¡é ¼åº¦
        
        # è£…å‚™ãƒ•ãƒ©ã‚°
        1 if "ã‚µãƒ³ãƒ«ãƒ¼ãƒ•" in title else 0,
        1 if any(kw in title for kw in ["ãƒ¬ã‚¶ãƒ¼", "é©ã‚·ãƒ¼ãƒˆ", "æœ¬é©"]) else 0,
        1 if any(kw in title for kw in ["BOSE", "JBL", "ãƒãƒ¼ã‚¯ãƒ¬ãƒ“ãƒ³ã‚½ãƒ³"]) else 0,
        1 if any(kw in title for kw in ["4WD", "AWD", "å››é§†"]) else 0,
        1 if "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰" in title else 0,
        1 if "ã‚¿ãƒ¼ãƒœ" in title else 0,
        1 if item.get("has_repair", False) else 0,
        
        # ãƒ¢ãƒ‡ãƒ«åˆ¥ãƒ€ãƒŸãƒ¼å¤‰æ•°ï¼ˆä¸»è¦ãƒ¢ãƒ‡ãƒ«ï¼‰
        1 if "ãƒãƒªã‚¢ãƒ¼" in title else 0,
        1 if "RAV4" in title else 0,
        1 if "CX-5" in title else 0,
        1 if "ãƒ•ã‚©ãƒ¬ã‚¹ã‚¿ãƒ¼" in title else 0,
        1 if "ã‚¨ã‚¯ã‚¹ãƒˆãƒ¬ã‚¤ãƒ«" in title else 0,
    ]
    
    return features

def predict_quantiles(items: List[Dict[str, Any]], quantiles=(0.5, 0.2)) -> Dict[float, np.ndarray]:
    """åˆ†ä½å›å¸°ã«ã‚ˆã‚‹ä¾¡æ ¼äºˆæ¸¬"""
    if len(items) < 20:
        return {q: np.array([None] * len(items)) for q in quantiles}
    
    X = np.array([build_features(item) for item in items])
    y = np.array([item.get("price", 0) for item in items])
    
    # ä¾¡æ ¼ãŒ0ã®é …ç›®ã‚’é™¤å¤–
    valid_mask = y > 0
    if valid_mask.sum() < 15:
        return {q: np.array([None] * len(items)) for q in quantiles}
    
    predictions = {}
    
    for q in quantiles:
        preds = np.full(len(items), np.nan)
        kf = KFold(n_splits=min(5, valid_mask.sum() // 3), shuffle=True, random_state=42)
        
        try:
            for train_idx, val_idx in kf.split(X[valid_mask]):
                # æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
                valid_indices = np.where(valid_mask)[0]
                train_indices = valid_indices[train_idx]
                val_indices = valid_indices[val_idx]
                
                model = GradientBoostingRegressor(
                    loss="quantile",
                    alpha=q,
                    n_estimators=100,
                    max_depth=4,
                    learning_rate=0.1,
                    random_state=42
                )
                
                model.fit(X[train_indices], y[train_indices])
                preds[val_indices] = model.predict(X[val_indices])
            
        except Exception as e:
            print(f"[WARN] Quantile regression failed: {e}")
            return {q: np.array([None] * len(items)) for q in quantiles}
        
        predictions[q] = preds
    
    return predictions

# ========== Discordé€šçŸ¥ï¼ˆæ”¹è‰¯ç‰ˆï¼‰ ==========
def send_discord_notification(items: List[Dict[str, Any]], webhook_url: str, category: str):
    """Discordé€šçŸ¥é€ä¿¡"""
    if not items:
        print(f"[INFO] {category}: é€šçŸ¥å¯¾è±¡ãªã—")
        return
    
    if os.getenv("DISCORD_DRY_RUN", "0") == "1":
        print(f"[DRY-RUN] {category} é€šçŸ¥:")
        for item in items[:3]:
            print(f"  - {item['title'][:50]}... Score:{item['score']} Price:{item['price']:,}å††")
        return
    
    if not webhook_url:
        print(f"[WARN] {category}: Webhook URLæœªè¨­å®š")
        return
    
    embeds = []
    for item in items[:5]:
        price = item.get("price", 0)
        year = item.get("year", 0)
        mileage = item.get("mileage", 0)
        
        fields = [
            {"name": "ä¾¡æ ¼", "value": f"{price:,}å††", "inline": True},
            {"name": "å¹´å¼", "value": f"{year}å¹´", "inline": True},
            {"name": "èµ°è¡Œè·é›¢", "value": f"{mileage:,}km", "inline": True},
            {"name": "ã‚¹ã‚³ã‚¢", "value": f"{item.get('score', 0):.1f}", "inline": True},
            {"name": "ç·Šæ€¥åº¦", "value": "ğŸ”¥" * item.get("urgency", 1), "inline": True},
            {"name": "SUVåˆ¤å®š", "value": f"{item.get('model_name', 'ä¸æ˜')} ({item.get('confidence', 0):.0%})", "inline": True},
        ]
        
        if item.get("price_ratio"):
            fields.append({"name": "ç›¸å ´æ¯”", "value": f"{item['price_ratio']:.0%}", "inline": True})
        
        if item.get("deal_gap"):
            fields.append({"name": "äºˆæ¸¬å·®é¡", "value": f"+{item['deal_gap']:,}å††", "inline": True})
        
        color = 0xFF0000 if item.get("urgency", 1) >= 4 else 0xFFAA00 if item.get("urgency", 1) >= 3 else 0x00AA00
        
        embeds.append({
            "title": item.get("title", "ä¸æ˜")[:256],
            "url": item.get("url", ""),
            "color": color,
            "fields": fields,
            "footer": {"text": f"{item.get('site', '')} | {item.get('grade', '')}"}
        })
    
    payload = {
        "content": f"**{category}** - {datetime.now():%Y/%m/%d %H:%M}",
        "embeds": embeds
    }
    
    try:
        response = requests.post(webhook_url, json=payload, timeout=10)
        response.raise_for_status()
        print(f"[SUCCESS] {category}: {len(items)}ä»¶é€šçŸ¥å®Œäº†")
    except Exception as e:
        print(f"[ERROR] Discordé€šçŸ¥å¤±æ•— ({category}): {e}")

# ========== ç›£è¦–è¨­å®š ==========
MONITORING_CONFIGS = [
    {
        "name": "ãƒˆãƒ¨ã‚¿SUV",
        "site": "carsensor",
        "base_url": "https://www.carsensor.net/usedcar/bTO/index.html",
        "params": {
            "SORT": "22",  # æ–°ç€é †
            "SHASHU": "ãƒãƒªã‚¢ãƒ¼|RAV4|ãƒ©ãƒ³ãƒ‰ã‚¯ãƒ«ãƒ¼ã‚¶ãƒ¼|C-HR|ã‚«ãƒ­ãƒ¼ãƒ©ã‚¯ãƒ­ã‚¹|ãƒ¤ãƒªã‚¹ã‚¯ãƒ­ã‚¹"
        },
        "price_max": 5000000,
        "year_min": 2015,
        "mileage_max": 100000,
        "pages": 2
    },
    {
        "name": "ãƒãƒ„ãƒ€SUV",
        "site": "carsensor",
        "base_url": "https://www.carsensor.net/usedcar/bMA/index.html",
        "params": {
            "SORT": "22",
            "BODY": "SUV"
        },
        "price_max": 4000000,
        "year_min": 2016,
        "mileage_max": 80000,
        "pages": 2
    },
    {
        "name": "ã‚¹ãƒãƒ«SUV",
        "site": "carsensor",
        "base_url": "https://www.carsensor.net/usedcar/bSU/index.html",
        "params": {
            "SORT": "22",
            "SHASHU": "ãƒ•ã‚©ãƒ¬ã‚¹ã‚¿ãƒ¼|XV|ãƒ¬ã‚¬ã‚·ã‚£ã‚¢ã‚¦ãƒˆãƒãƒƒã‚¯|ã‚¢ã‚¦ãƒˆãƒãƒƒã‚¯"
        },
        "price_max": 4000000,
        "year_min": 2015,
        "mileage_max": 90000,
        "pages": 2
    },
    {
        "name": "æ—¥ç”£ãƒ»ãƒ›ãƒ³ãƒ€SUV",
        "site": "carsensor",
        "base_url": "https://www.carsensor.net/usedcar/index.html",
        "params": {
            "MAKER": "NI|HO",  # æ—¥ç”£ãƒ»ãƒ›ãƒ³ãƒ€
            "BODY": "SUV",
            "SORT": "22"
        },
        "price_max": 4500000,
        "year_min": 2015,
        "mileage_max": 100000,
        "pages": 2
    },
    {
        "name": "Goo-net SUV",
        "site": "goonet",
        "base_url": "https://www.goo-net.com/usedcar/",
        "params": {
            "body_type": "suv",
            "sort": "update_desc"
        },
        "price_max": 5000000,
        "year_min": 2015,
        "mileage_max": 100000,
        "pages": 1
    }
]

# ========== ãƒ¡ã‚¤ãƒ³å‡¦ç† ==========
def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=" * 60)
    print("SUVç‰¹åŒ–å‹ä¸­å¤è»Šã‚¹ã‚«ã‚¦ãƒˆ - èµ·å‹•")
    print(f"å®Ÿè¡Œæ™‚åˆ»: {datetime.now():%Y-%m-%d %H:%M:%S}")
    print("=" * 60)
    
    # ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
    webhook_main = os.getenv("DISCORD_WEBHOOK_URL_MAIN") or os.getenv("DISCORD_WEBHOOK_URL")
    webhook_maybe = os.getenv("DISCORD_WEBHOOK_URL_MAYBE")
    immediate_min = int(os.getenv("IMMEDIATE_URGENCY_MIN", "4"))
    maybe_score_min = float(os.getenv("MAYBE_SCORE_MIN", "70"))
    maybe_score_max = float(os.getenv("MAYBE_SCORE_MAX", "84.9"))
    
    # ã‚«ã‚¹ã‚¿ãƒ è¨­å®šãŒã‚ã‚Œã°èª­ã¿è¾¼ã¿
    custom_config = os.getenv("TARGETS_JSON")
    if custom_config:
        try:
            MONITORING_CONFIGS.clear()
            MONITORING_CONFIGS.extend(json.loads(custom_config))
            print(f"[INFO] ã‚«ã‚¹ã‚¿ãƒ è¨­å®šã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
        except Exception as e:
            print(f"[ERROR] TARGETS_JSONè§£æã‚¨ãƒ©ãƒ¼: {e}")
    
    all_vehicles = []
    classifier = VehicleClassifier()
    
    # å„è¨­å®šã§ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
    for config in MONITORING_CONFIGS:
        print(f"\n[å‡¦ç†ä¸­] {config['name']}")
        
        site = config["site"]
        if site == "carsensor":
            parser = parse_carsensor_list_enhanced
        elif site == "goonet":
            parser = parse_goonet_list_enhanced
        else:
            print(f"[SKIP] æœªå¯¾å¿œã‚µã‚¤ãƒˆ: {site}")
            continue
        
        vehicles = []
        
        for page in range(1, config.get("pages", 1) + 1):
            # URLæ§‹ç¯‰
            url = config["base_url"]
            if config.get("params"):
                param_str = "&".join([f"{k}={v}" for k, v in config["params"].items()])
                url += ("&" if "?" in url else "?") + param_str
            if page > 1:
                url += f"&page={page}"
            
            print(f"  å–å¾—ä¸­: {url}")
            html = fetch_with_retry(url)
            if not html:
                continue
            
            # ãƒ‘ãƒ¼ã‚¹
            items = parser(html)
            print(f"  â†’ {len(items)}ä»¶å–å¾—")
            
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            filtered = []
            for item in items:
                # ä¾¡æ ¼ãƒ»å¹´å¼ãƒ»èµ°è¡Œè·é›¢ãƒ•ã‚£ãƒ«ã‚¿
                if item.get("price", 0) > config.get("price_max", 9999999):
                    continue
                if item.get("year", 0) < config.get("year_min", 0):
                    continue
                if item.get("mileage", 0) > config.get("mileage_max", 9999999):
                    continue
                
                # SUVç¢ºèªï¼ˆè©³ç´°ãƒã‚§ãƒƒã‚¯ï¼‰
                if item.get("confidence", 0) < 0.5:
                    # ä¿¡é ¼åº¦ãŒä½ã„å ´åˆã¯è©³ç´°ãƒšãƒ¼ã‚¸ã‚’ç¢ºèª
                    details = extract_vehicle_details(item["url"], site)
                    if details:
                        detailed_text = details.get("description", "") + " " + details.get("body_type", "")
                        is_suv, model, conf = classifier.classify(item["title"], detailed_text)
                        
                        if is_suv and conf >= 0.5:
                            item["model_name"] = model
                            item["confidence"] = conf
                            item.update(details)
                        else:
                            continue  # SUVã§ãªã„
                
                filtered.append(item)
            
            vehicles.extend(filtered)
            print(f"  â†’ ãƒ•ã‚£ãƒ«ã‚¿å¾Œ: {len(filtered)}ä»¶")
        
        if not vehicles:
            print(f"  â†’ è©²å½“è»Šä¸¡ãªã—")
            continue
        
        # å¸‚å ´çµ±è¨ˆè¨ˆç®—
        prices = [v["price"] for v in vehicles if v.get("price", 0) > 0]
        if len(prices) >= 5:
            market_stats = {
                "median": np.median(prices),
                "q25": np.percentile(prices, 25),
                "q75": np.percentile(prices, 75),
                "mean": np.mean(prices),
                "std": np.std(prices)
            }
            print(f"  å¸‚å ´çµ±è¨ˆ: ä¸­å¤®å€¤ {market_stats['median']:,.0f}å††")
        else:
            market_stats = {}
        
        # äºˆæ¸¬ä¾¡æ ¼è¨ˆç®—
        if len(vehicles) >= 20:
            predictions = predict_quantiles(vehicles)
            for i, vehicle in enumerate(vehicles):
                vehicle["pred_p50"] = predictions[0.5][i] if not np.isnan(predictions[0.5][i]) else None
                vehicle["pred_p20"] = predictions[0.2][i] if not np.isnan(predictions[0.2][i]) else None
        
        # ã‚¹ã‚³ã‚¢è¨ˆç®—
        for vehicle in vehicles:
            compute_enhanced_score(vehicle, market_stats, config)
        
        all_vehicles.extend(vehicles)
    
    # å…¨ä½“ã§ã‚½ãƒ¼ãƒˆ
    all_vehicles.sort(key=lambda x: (x.get("urgency", 0), x.get("score", 0)), reverse=True)
    
    # CSVå‡ºåŠ›
    print("\n[CSVå‡ºåŠ›]")
    with open("suv_results.csv", "w", newline="", encoding="utf-8-sig") as f:
        writer = csv.writer(f)
        writer.writerow([
            "ã‚¿ã‚¤ãƒˆãƒ«", "URL", "ã‚µã‚¤ãƒˆ", "ãƒ¢ãƒ‡ãƒ«", "ä¿¡é ¼åº¦",
            "ä¾¡æ ¼", "å¹´å¼", "èµ°è¡Œè·é›¢", "ã‚¹ã‚³ã‚¢", "ç·Šæ€¥åº¦",
            "ç›¸å ´æ¯”", "äºˆæ¸¬å·®é¡", "ã‚°ãƒ¬ãƒ¼ãƒ‰"
        ])
        
        for v in all_vehicles[:30]:
            writer.writerow([
                v.get("title", ""),
                v.get("url", ""),
                v.get("site", ""),
                v.get("model_name", ""),
                f"{v.get('confidence', 0):.0%}",
                v.get("price", 0),
                v.get("year", 0),
                v.get("mileage", 0),
                v.get("score", 0),
                v.get("urgency", 0),
                f"{v.get('price_ratio', 0):.0%}" if v.get("price_ratio") else "",
                v.get("deal_gap", ""),
                v.get("grade", "")
            ])
    print(f"  â†’ suv_results.csv ã«ä¸Šä½30ä»¶ã‚’ä¿å­˜")
    
    # Discordé€šçŸ¥æº–å‚™
    immediate_items = [v for v in all_vehicles if v.get("urgency", 0) >= immediate_min]
    maybe_items = [v for v in all_vehicles 
                   if v.get("urgency", 0) == 3 or 
                   (maybe_score_min <= v.get("score", 0) <= maybe_score_max)]
    
    # é‡è¤‡é™¤å»
    immediate_urls = {v["url"] for v in immediate_items}
    maybe_items = [v for v in maybe_items if v["url"] not in immediate_urls]
    
    # é€šçŸ¥é€ä¿¡
    print("\n[Discordé€šçŸ¥]")
    send_discord_notification(immediate_items[:5], webhook_main, "ğŸš€ å³è²·ã„ãƒ¬ãƒ™ãƒ« SUV")
    send_discord_notification(maybe_items[:5], webhook_maybe, "ğŸ¤” æ¤œè¨ä¾¡å€¤ã‚ã‚Š SUV")
    
    print("\n[å®Œäº†]")
    print(f"  å³è²·ã„å€™è£œ: {len(immediate_items)}ä»¶")
    print(f"  æ¤œè¨å€™è£œ: {len(maybe_items)}ä»¶")
    print(f"  ç·å–å¾—æ•°: {len(all_vehicles)}ä»¶")

if __name__ == "__main__":
    main()
